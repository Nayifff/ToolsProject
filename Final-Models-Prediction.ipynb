{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for cleaning & exploring the dataset, and then run 6 different models: Decision Tree, Logistic Regression, Nearest Neighbor, Random Forest, XGBoost and SVM. Scores are given at the last cell\n",
    "\n",
    "## Please scroll down to test our single song prediction! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model: Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('compiled_cleaned_songs.csv', sep = ',')\n",
    "train = df.drop(['Unnamed: 0','Artist', 'Track', 'Year','Key'], axis=1)\n",
    "x = train.drop(\"Hot\", axis=1)\n",
    "y = train['Hot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1855   96]\n",
      " [  99  116]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      1951\n",
      "          1       0.55      0.54      0.54       215\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76239073 0.71280925 0.7691411  0.71580866 0.74890443 0.7441459\n",
      " 0.73994806 0.77551532 0.72171071 0.75629676]\n",
      "Mean: 0.7446670928309218\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(), X_train, y_train, cv=10, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "DTscore=scores.mean()\n",
    "DTf1score=f1_score(y_test, y_pred, average=None)\n",
    "print(\"Mean:\", DTscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85262238 0.84675866 0.84484972 0.83443259 0.84784501 0.86581677\n",
      " 0.76642616 0.85711124 0.79379694 0.79238045]\n",
      "Mean: 0.8302039918530998\n",
      "[[1926   25]\n",
      " [ 183   32]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95      1951\n",
      "          1       0.56      0.15      0.24       215\n",
      "\n",
      "avg / total       0.88      0.90      0.88      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred2 = LR.predict(X_test)  \n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=10, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "LRscore=scores.mean()\n",
    "LRf1score=f1_score(y_test, y_pred2, average=None)\n",
    "print(\"Mean:\", LRscore)\n",
    "print(confusion_matrix(y_test, y_pred2))  \n",
    "print(classification_report(y_test, y_pred2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model: Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57956731 0.62512399 0.6060378  0.62240863 0.5814705  0.65925221\n",
      " 0.63197734 0.61031679 0.64332404 0.67364585]\n",
      "Mean: 0.6233124453002252\n",
      "[[1945    6]\n",
      " [ 211    4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95      1951\n",
      "          1       0.40      0.02      0.04       215\n",
      "\n",
      "avg / total       0.85      0.90      0.86      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "nnc = KNeighborsClassifier(n_neighbors = 7)\n",
    "nnc.fit(X_train, y_train)\n",
    "y_pred3 = nnc.predict(X_test)  \n",
    "scores = cross_val_score(nnc, X_train, y_train, cv=10, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "nncscore=scores.mean()\n",
    "nncf1score=f1_score(y_test, y_pred3, average=None)\n",
    "print(\"Mean:\", nncscore)\n",
    "print(confusion_matrix(y_test, y_pred3))\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87918124 0.89484625 0.90013722 0.90843699 0.89789444 0.87601257\n",
      " 0.8803432  0.94981777 0.86280672 0.90528677]\n",
      "Mean: 0.8954763174739326\n",
      "[[1918   33]\n",
      " [ 124   91]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96      1951\n",
      "          1       0.73      0.42      0.54       215\n",
      "\n",
      "avg / total       0.92      0.93      0.92      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfe = RandomForestClassifier()\n",
    "rfe.fit(X_train, y_train)\n",
    "y_pred4 = rfe.predict(X_test) \n",
    "scores = cross_val_score(rfe, X_train, y_train, cv=10, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "rfescore=scores.mean()\n",
    "rfef1score=f1_score(y_test, y_pred4, average=None)\n",
    "print(\"Mean:\", rfescore)\n",
    "print(confusion_matrix(y_test, y_pred4))  \n",
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Model: XGBOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varun Bhatia\\Anaconda4\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95909091 0.94452387 0.93034099 0.94860785 0.95244419 0.94398949\n",
      " 0.92883597 0.96504508 0.93646437 0.94609948]\n",
      "Mean: 0.9455442198086393\n",
      "[[1912   39]\n",
      " [  96  119]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      1951\n",
      "          1       0.75      0.55      0.64       215\n",
      "\n",
      "avg / total       0.93      0.94      0.93      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred5 = xgb.predict(X_test) \n",
    "scores = cross_val_score(xgb, X_train, y_train, cv=10, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "xgbscore=scores.mean()\n",
    "xgbf1score=f1_score(y_test, y_pred5, average=None)\n",
    "print(\"Mean:\", xgbscore)\n",
    "print(confusion_matrix(y_test, y_pred5))  \n",
    "print(classification_report(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth Model: SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50317599 0.44895845 0.49807445 0.42921222 0.46443274 0.43265017\n",
      " 0.39616071 0.40665162 0.42754489 0.42001977]\n",
      "Mean: 0.44268810260682023\n",
      "[[  22 1929]\n",
      " [   0  215]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.01      0.02      1951\n",
      "          1       0.10      1.00      0.18       215\n",
      "\n",
      "avg / total       0.91      0.11      0.04      2166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred6 = svc.predict(X_test) \n",
    "scores = cross_val_score(svc, X_train, y_train, cv=10, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "svcscore=scores.mean()\n",
    "svcf1score=f1_score(y_test, y_pred6, average=None)\n",
    "print(\"Mean:\", svcscore)\n",
    "print(confusion_matrix(y_test, y_pred6))  \n",
    "print(classification_report(y_test, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Score</th>\n",
       "      <th>F-1 Score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.744667</td>\n",
       "      <td>0.543326</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.830204</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.623312</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>Nearest Neighbor Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.895476</td>\n",
       "      <td>0.536873</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.945544</td>\n",
       "      <td>0.638070</td>\n",
       "      <td>XGBOOST CLASSIFIER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.442688</td>\n",
       "      <td>0.182281</td>\n",
       "      <td>SUPPORT VECTOR MACHINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Score  F-1 Score                        Model\n",
       "0    0.744667   0.543326                Decision Tree\n",
       "1    0.830204   0.235294          Logistic Regression\n",
       "2    0.623312   0.035556  Nearest Neighbor Classifier\n",
       "3    0.895476   0.536873     Random Forest Classifier\n",
       "4    0.945544   0.638070           XGBOOST CLASSIFIER\n",
       "5    0.442688   0.182281       SUPPORT VECTOR MACHINE"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Mean Score': [DTscore, LRscore, nncscore, rfescore, xgbscore, svcscore] ,'F-1 Score': [DTf1score[1], LRf1score[1], nncf1score[1], rfef1score[1], xgbf1score[1],svcf1score[1]], 'Model': ['Decision Tree', 'Logistic Regression', \n",
    "              'Nearest Neighbor Classifier','Random Forest Classifier','XGBOOST CLASSIFIER','SUPPORT VECTOR MACHINE']}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Song Prediction based on xgboost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the artist name? Martin Solveig\n",
      "What is the track name? All stars\n",
      "Please run the next cell to see whether the inserted song will be in Billboard or not!\n"
     ]
    }
   ],
   "source": [
    "# Make sure you run the logistic regression model on top first\n",
    "# If you dont have songs in mind: Please try: Ed Sheeran - Shape Of You, and Duke Dumont - Ocean Drive\n",
    "artist = input(\"What is the artist name? \")\n",
    "track = input(\"What is the track name? \")\n",
    "print('Please run the next cell to see whether the inserted song will be in Billboard or not!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=[0]\n",
      "We are sorry to tell you that the song you chose, most probably, wont be in Billboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varun Bhatia\\Anaconda4\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "import numpy as np\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "songs_features=[]\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=\"a31e2c1446fd4e6aa11476d8532fc939\",client_secret=\"b52f884f9d4f464eba58daf0d5180ea4\")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "from collections import OrderedDict\n",
    "try:\n",
    "    songs=sp.search(q=\"track:\"+str(track)+\" \"+'artist:'+str(artist)+'*' , type='track')\n",
    "    items = songs['tracks']['items']\n",
    "    track2 = items[0]\n",
    "    song_id = str(track2[\"id\"])\n",
    "    track_features=sp.audio_features(song_id)\n",
    "    features = np.array(track_features)[0]\n",
    "    danceability, energy, key, loudness, mode,speechiness,acousticness, instrumentalness, liveness, valence, tempo, type_, id_,uri, track_href,analysis_url,duration_ms, time_signature=features.values()\n",
    "    track_info = sp.track(uri)\n",
    "    track_pop=track_info['popularity']\n",
    "    artists=sp.search('artist:'+str(artist)+'*' , type='artist')\n",
    "    try: \n",
    "        artist_popularity = artists['artists']['items'][0]['popularity']\n",
    "    except: \n",
    "        artist_popularity = 0 \n",
    "    songs_features.append((danceability, energy, loudness, mode, speechiness,acousticness, instrumentalness, liveness, valence, tempo,duration_ms,time_signature,track_pop, artist_popularity))\n",
    "except:\n",
    "    print('Opps... it seems that the track or artist is incorrect!')\n",
    "\n",
    "columns_ = [\"Danceability\",\"Energy\", \"Loudness\", \"Mode\", \"Speechiness\", \"Acousticness\",\n",
    "          \"Instrumentalness\", \"Liveness\", \"Valence\", \"Tempo\",\"Duration_ms\", \"Time_Signature\",'Track_Popularity',\"Artist_Popularity\"]\n",
    "xnew =pd.DataFrame(songs_features, columns=columns_)\n",
    "\n",
    "ynew = xgb.predict(xnew)\n",
    "\n",
    "print(\"Predicted=%s\" % (ynew))\n",
    "\n",
    "if ynew == 0.0: \n",
    "    print('We are sorry to tell you that the song you chose, most probably, wont be in Billboard')\n",
    "else: \n",
    "    print('It seems like the song you chose will most probably appear in Billboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
